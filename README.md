# Intelligent Battery Monitoring System with Uncertainty Quantification

A comprehensive machine learning system for predicting Remaining Useful Life (RUL) of batteries with uncertainty quantification using statistical features and Empirical Mode Decomposition (EMD).

## ğŸ¯ Project Overview

This project implements an intelligent battery monitoring system that predicts battery RUL with confidence intervals using:
- **Statistical Features**: Voltage, current, temperature statistics from cycle waveforms (16 features)
- **EMD Features**: Empirical Mode Decomposition to capture multi-scale temporal patterns (159 features)
- **Multiple Models**: Random Forest, LSTM (PyTorch), and Transformer for point predictions
- **Uncertainty Quantification**: Monte Carlo Dropout for LSTM using PyTorch (Phase 2)
- **Total Features**: 175 features per cycle (16 statistical + 159 EMD features)
- **Visualization**: Multi-audience visualization pipeline for data insights and model results

## ğŸ“Š Dataset

Uses NASA/CALCE battery datasets with:
- 2,750 discharge cycles
- 34 unique batteries
- Multi-scale temporal features extracted via EMD

## ğŸš€ Project Structure

### Phase 1: Point Prediction Models (Baseline Comparison)
Compare Random Forest, LSTM, and Transformer models on point predictions:
1. **Random Forest** - Point prediction with feature importance
2. **LSTM** - Sequence-based point prediction
3. **Transformer** - Attention-based point prediction
4. **Model Comparison** - Compare all 3 models on test set

### Phase 2: Uncertainty Quantification (LSTM Only)
Add Monte Carlo Dropout to LSTM model:
- 100 forward passes with dropout enabled at inference
- Extract mean and std from predictions
- Calculate prediction intervals (5th, 25th, 75th, 95th percentiles)
- Evaluate uncertainty calibration

## ğŸ“ Project Structure

```
Battery_RUL/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features/          # Feature extraction modules
â”‚   â”‚   â”œâ”€â”€ emd_extractor.py
â”‚   â”‚   â””â”€â”€ feature_pipeline.py
â”‚   â”œâ”€â”€ models/            # Model implementations (to be created)
â”‚   â””â”€â”€ visualization/     # Plotting utilities (to be created)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploration/       # Data exploration notebooks
â”‚   â”‚   â””â”€â”€ Data_Exploration2.ipynb                 âœ… Data preprocessing
â”‚   â”œâ”€â”€ modeling/          # Model training notebooks
â”‚   â”‚   â”œâ”€â”€ 01_extract_emd_features.ipynb          âœ… EMD feature extraction
â”‚   â”‚   â”œâ”€â”€ 02_train_random_forest_point.ipynb      âœ… Random Forest (point)
â”‚   â”‚   â”œâ”€â”€ 03_train_lstm_pytorch.ipynb             âœ… LSTM (PyTorch, point)
â”‚   â”‚   â”œâ”€â”€ 06_add_uncertainty_lstm_mc_pytorch.ipynb âœ… MC Dropout (PyTorch)
â”‚   â”‚   â””â”€â”€ 04_train_transformer_point.ipynb         â† Transformer (pending)
â”‚   â””â”€â”€ evaluation/        # Visualization and evaluation notebooks
â”‚       â””â”€â”€ 01_dataset_insights_visualization.ipynb  âœ… Level 1 visualizations
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/         # Processed datasets
â”‚   â”‚   â”œâ”€â”€ rul_features.csv
â”‚   â”‚   â””â”€â”€ rul_features_with_emd.parquet
â”‚   â”œâ”€â”€ raw/              # Raw data
â”‚   â””â”€â”€ external/         # External data sources
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ models/           # Saved models (.pkl, .pth, .h5)
â”‚   â”œâ”€â”€ visualizations/   # Generated plots and figures
â”‚   â””â”€â”€ reports/          # Evaluation reports
â”œâ”€â”€ dashboard/            # Web dashboard (coming soon)
â””â”€â”€ docs/                 # Documentation
    â”œâ”€â”€ PROJECT_ROADMAP.md
    â”œâ”€â”€ MODELING_SEQUENCE.md
    â””â”€â”€ NEXT_STEPS.md
```

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/Siddhant2512/Intelligent-Battery-Monitoring.git
cd Intelligent-Battery-Monitoring
```

2. Create virtual environment:
```bash
python -m venv battery_env
source battery_env/bin/activate  # On Windows: battery_env\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ“ Usage

### Phase 1: Point Prediction Models

#### 1. Extract EMD Features
```bash
jupyter notebook notebooks/modeling/01_extract_emd_features.ipynb
```

#### 2. Train Random Forest Model
```bash
jupyter notebook notebooks/modeling/02_train_random_forest_point.ipynb
```

#### 3. Train LSTM Model (PyTorch)
```bash
jupyter notebook notebooks/modeling/03_train_lstm_pytorch.ipynb
```
**Note**: Uses PyTorch with MPS acceleration for Apple Silicon (much faster than TensorFlow)

#### 4. Train Transformer Model
```bash
jupyter notebook notebooks/modeling/04_train_transformer_point.ipynb
```

#### 5. Compare All Models
```bash
jupyter notebook notebooks/modeling/05_compare_models_point.ipynb
```

### Phase 2: Uncertainty Quantification (LSTM Only)

#### 6. Add Monte Carlo Dropout to LSTM (PyTorch)
```bash
jupyter notebook notebooks/modeling/06_add_uncertainty_lstm_mc_pytorch.ipynb
```

### Visualization

#### 7. Generate Dataset Insights Visualizations
```bash
jupyter notebook notebooks/evaluation/01_dataset_insights_visualization.ipynb
```
Creates publication-quality visualizations for data understanding (Level 1).

## ğŸ“ˆ Results

### Data Preprocessing

The preprocessing pipeline transforms raw battery cycle data into a structured dataset:

- **Input**: 2,750 discharge cycles from 34 unique batteries
- **Processing Steps**:
  1. Filter discharge cycles with valid capacity measurements
  2. Calculate cycle index, SOH (State of Health), and EOL (End of Life) cycle
  3. Compute RUL (Remaining Useful Life) as `EOL_cycle - cycle_index`
  4. Extract statistical features from cycle waveforms (16 features)
  5. Apply Empirical Mode Decomposition (EMD) to extract multi-scale patterns (159 features)
  6. Create battery-level train/val/test splits (70/15/15) to prevent data leakage

- **Output**: 
  - `rul_features_with_emd.parquet`: 2,750 rows Ã— 190 columns
  - 1,408 rows with valid RUL labels (batteries that reached EOL)
  - RUL range: -107 to 123 cycles

### Phase 1: Point Predictions

#### Random Forest Model âœ…

**Configuration**:
- 100 decision trees
- Max depth: 20
- Min samples split: 5
- Min samples leaf: 2
- Features: 175 (statistical + EMD)

**Performance** (Test Set):
- **MAE**: ~21-22 cycles
- **RMSE**: ~27-28 cycles
- **RÂ²**: ~0.99 (train), ~-0.04 to 0.0 (test)
- **Training Time**: < 1 second

**Key Insights**:
- Excellent training fit (RÂ² â‰ˆ 0.99) indicating model capacity
- Test performance suggests overfitting or distribution shift
- Feature importance analysis reveals voltage and capacity metrics as top predictors
- EMD features contribute to model performance, validating feature engineering

**Model Artifacts**:
- Saved model: `results/models/random_forest_rul_point_model.pkl`
- Predictions: `results/models/rf_predictions_point.csv`
- Metrics: `results/models/rf_metrics_point.csv`

#### LSTM Model (PyTorch) âœ…

**Configuration**:
- Architecture: LSTM(64) â†’ LSTM(32) â†’ Dense(16) â†’ Dense(1)
- Sequence length: 20 cycles
- Dropout: 0.2 (for MC Dropout in Phase 2)
- Optimizer: Adam (lr=0.001)
- Training: MPS acceleration on Apple Silicon

**Performance**: Training completed successfully (results pending full evaluation)


#### Transformer Model
- Status: Pending implementation

### Phase 2: Uncertainty Quantification (LSTM)

#### Monte Carlo Dropout (PyTorch) âœ…
- **Method**: 100 forward passes with dropout enabled during inference
- **Output**: Mean predictions, standard deviation, and prediction intervals
- **Implementation**: Simple `model.train()` during inference (PyTorch advantage)
- Status: Notebook ready, pending LSTM model training completion

## ğŸ”¬ Methodology

### Data Preprocessing Pipeline

1. **Metadata Processing**:
   - Load battery metadata with capacity measurements
   - Filter discharge cycles with valid capacity (> 0)
   - Coerce numeric columns (Capacity, Re, Rct) handling mixed data types
   - Calculate cycle index per battery

2. **RUL Label Generation**:
   - Compute initial capacity per battery
   - Calculate SOH (State of Health) = Current Capacity / Initial Capacity
   - Identify EOL cycle (first cycle where SOH â‰¤ 0.8)
   - Calculate RUL = EOL_cycle - cycle_index
   - Handle batteries that don't reach EOL (NaN RUL)

3. **Feature Extraction**:
   - **Statistical Features** (16 features):
     - Voltage: mean, min, max
     - Current: mean absolute value
     - Temperature: max
     - Duration, coulomb count (Ah), IR drop proxy
   
   - **EMD Features** (159 features):
     - Empirical Mode Decomposition of voltage, current, temperature signals
     - Extract up to 5 IMFs (Intrinsic Mode Functions) per signal
     - For each IMF: energy, mean, std, skewness, kurtosis
     - Total: 3 signals Ã— 5 IMFs Ã— 5 statistics Ã— 2 (if applicable) â‰ˆ 159 features

4. **Data Splitting**:
   - Battery-level splits (70% train, 15% val, 15% test)
   - Prevents data leakage by ensuring same battery doesn't appear in multiple splits
   - Handles edge cases (empty validation set when batteries don't reach EOL)

### Uncertainty Quantification (LSTM Only - PyTorch)
- **Monte Carlo Dropout**: 
  - Simple implementation: `model.train()` during inference
  - Run 100 forward passes with dropout enabled
  - Extract mean and standard deviation from predictions
  - Calculate prediction intervals (5th, 25th, 75th, 95th percentiles)
  - Evaluate uncertainty calibration (coverage metrics)

### Model Evaluation
- **Point Prediction Metrics**: MAE, RMSE, MAPE, RÂ²
- **Uncertainty Metrics** (LSTM): Prediction Interval Coverage (90%, 50%), Average Interval Width
- **Visualizations**: 
  - Level 1: Dataset insights (capacity fade, correlations, distributions)
  - Model performance plots (predictions vs actual, residuals)
  - Uncertainty visualization (confidence intervals, calibration curves)

## ğŸ“Š Visualization

### Level 1: Dataset Insights âœ…

Comprehensive visualizations demonstrating data understanding:

1. **Capacity Fade Over Cycles**: Tracks degradation patterns across multiple batteries
2. **Feature Correlation Heatmap**: Reveals relationships between operational signals and capacity
3. **Distribution Plots**: Statistical analysis of key features (voltage, capacity, EMD features)
4. **SOH vs RUL Relationship**: Validates RUL calculation methodology

All visualizations are publication-quality (300 DPI) and saved to `results/visualizations/`.

### Level 2: Model Performance (Coming Soon)
- Predictions vs actual plots
- Residual analysis
- Feature importance visualizations

### Level 3: Uncertainty Visualization (Coming Soon)
- Confidence intervals
- Calibration curves
- Uncertainty vs error analysis

## ğŸ¨ Dashboard (Future)

Interactive web dashboard (coming soon) for:
- Real-time RUL predictions
- Confidence interval visualization (LSTM)
- Battery health monitoring
- Historical trend analysis

## ğŸ“š Documentation

- [Project Roadmap](docs/PROJECT_ROADMAP.md) - Complete project structure and phases
- [Modeling Sequence Guide](docs/MODELING_SEQUENCE.md) - Step-by-step modeling guide
- [Next Steps](docs/NEXT_STEPS.md) - Quick start guide

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ‘¤ Author

**Siddhant Aggarwal**

- GitHub: [@Siddhant2512](https://github.com/Siddhant2512)
- Repository: [Intelligent-Battery-Monitoring](https://github.com/Siddhant2512/Intelligent-Battery-Monitoring)

## ğŸ™ Acknowledgments

- NASA Battery Dataset
- CALCE Battery Research Group
- PyEMD library for Empirical Mode Decomposition

---

**Status**: 
- âœ… **Phase 1**: Random Forest and LSTM (PyTorch) models trained
- âœ… **Data Preprocessing**: Complete pipeline with EMD features
- âœ… **Visualization**: Level 1 dataset insights complete
- ğŸš§ **Phase 1**: Transformer model pending
- ğŸš§ **Phase 2**: MC Dropout evaluation pending
- ğŸš§ **Dashboard**: Web interface coming soon
