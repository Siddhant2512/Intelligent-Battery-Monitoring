{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Random Forest Model with Uncertainty Quantification\n",
        "\n",
        "This notebook trains a Random Forest model for RUL prediction with uncertainty quantification using quantile regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(\"/Users/siddhantaggarwal/Desktop/Battery_RUL\").resolve()\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (2750, 190)\n",
            "\n",
            "Splits distribution:\n",
            "split\n",
            "test      589\n",
            "train    1735\n",
            "val       426\n",
            "Name: count, dtype: int64\n",
            "\n",
            "After removing NaN RUL: 1408 rows\n",
            "RUL range: [-107.0, 123.0] cycles\n"
          ]
        }
      ],
      "source": [
        "# Load dataset with EMD features\n",
        "processed_dir = project_root / \"data\" / \"processed\"\n",
        "df = pd.read_parquet(processed_dir / \"rul_features_with_emd.parquet\")\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nSplits distribution:\")\n",
        "print(df['split'].value_counts().sort_index())\n",
        "\n",
        "# Filter out rows with NaN RUL (batteries that didn't reach EOL)\n",
        "df_clean = df[df['RUL'].notna()].copy()\n",
        "print(f\"\\nAfter removing NaN RUL: {len(df_clean)} rows\")\n",
        "print(f\"RUL range: [{df_clean['RUL'].min():.1f}, {df_clean['RUL'].max():.1f}] cycles\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total features: 175\n",
            "\n",
            "Feature categories:\n",
            "  - Statistical features: 16\n",
            "  - EMD features: 159\n",
            "\n",
            "Train: 1158, Val: 0, Test: 250\n",
            "Train RUL stats: mean=-0.25, std=44.31\n"
          ]
        }
      ],
      "source": [
        "# Prepare features and target\n",
        "# Exclude metadata columns\n",
        "exclude_cols = [\n",
        "    'battery_id', 'filename', 'type', 'start_time', 'test_id', 'uid',\n",
        "    'split', 'cycle_index', 'EOL_cycle', 'RUL', 'SOH', 'Capacity', \n",
        "    'Re', 'Rct', 'ambient_temperature'\n",
        "]\n",
        "\n",
        "feature_cols = [c for c in df_clean.columns if c not in exclude_cols]\n",
        "print(f\"Total features: {len(feature_cols)}\")\n",
        "print(f\"\\nFeature categories:\")\n",
        "emd_features = [c for c in feature_cols if '_imf' in c.lower()]\n",
        "stat_features = [c for c in feature_cols if c not in emd_features]\n",
        "print(f\"  - Statistical features: {len(stat_features)}\")\n",
        "print(f\"  - EMD features: {len(emd_features)}\")\n",
        "\n",
        "# Create feature matrix and target\n",
        "X = df_clean[feature_cols].fillna(0)  # Fill NaN with 0\n",
        "y = df_clean['RUL'].values\n",
        "\n",
        "# Split by battery (already done in dataset)\n",
        "train_idx = df_clean['split'] == 'train'\n",
        "val_idx = df_clean['split'] == 'val'\n",
        "test_idx = df_clean['split'] == 'test'\n",
        "\n",
        "X_train, y_train = X[train_idx], y[train_idx]\n",
        "X_val, y_val = X[val_idx], y[val_idx]\n",
        "X_test, y_test = X[test_idx], y[test_idx]\n",
        "\n",
        "print(f\"\\nTrain: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "print(f\"Train RUL stats: mean={y_train.mean():.2f}, std={y_train.std():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=11)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
            "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=11)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model trained!\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 175)) while a minimum of 1 is required by RandomForestRegressor.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Point predictions\u001b[39;00m\n\u001b[32m     17\u001b[39m y_train_pred = rf_model.predict(X_train)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m y_val_pred = \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m y_test_pred = rf_model.predict(X_test)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Metrics\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Battery_RUL/battery_env/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:1065\u001b[39m, in \u001b[36mForestRegressor.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1063\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[32m   1068\u001b[39m n_jobs, _, _ = _partition_estimators(\u001b[38;5;28mself\u001b[39m.n_estimators, \u001b[38;5;28mself\u001b[39m.n_jobs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Battery_RUL/battery_env/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:637\u001b[39m, in \u001b[36mBaseForest._validate_X_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    635\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X.indices.dtype != np.intc \u001b[38;5;129;01mor\u001b[39;00m X.indptr.dtype != np.intc):\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Battery_RUL/battery_env/lib/python3.13/site-packages/sklearn/utils/validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Battery_RUL/battery_env/lib/python3.13/site-packages/sklearn/utils/validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
            "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 175)) while a minimum of 1 is required by RandomForestRegressor."
          ]
        }
      ],
      "source": [
        "# Train Random Forest for point prediction\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "print(\"âœ… Model trained!\")\n",
        "\n",
        "# Point predictions\n",
        "y_train_pred = rf_model.predict(X_train)\n",
        "y_test_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Handle validation set (may be empty after filtering)\n",
        "if len(X_val) > 0:\n",
        "    y_val_pred = rf_model.predict(X_val)\n",
        "else:\n",
        "    print(\"âš ï¸  Validation set is empty after filtering NaN RUL values\")\n",
        "    y_val_pred = np.array([])\n",
        "\n",
        "# Metrics\n",
        "def calculate_metrics(y_true, y_pred, name):\n",
        "    if len(y_pred) == 0:\n",
        "        print(f\"\\n{name} Metrics: No data available\")\n",
        "        return {'mae': np.nan, 'rmse': np.nan, 'r2': np.nan, 'mape': np.nan}\n",
        "    \n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-6))) * 100\n",
        "    \n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(f\"  MAE:  {mae:.2f} cycles\")\n",
        "    print(f\"  RMSE: {rmse:.2f} cycles\")\n",
        "    print(f\"  RÂ²:   {r2:.3f}\")\n",
        "    print(f\"  MAPE: {mape:.2f}%\")\n",
        "    return {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}\n",
        "\n",
        "train_metrics = calculate_metrics(y_train, y_train_pred, \"Train\")\n",
        "if len(X_val) > 0:\n",
        "    val_metrics = calculate_metrics(y_val, y_val_pred, \"Validation\")\n",
        "else:\n",
        "    val_metrics = {'mae': np.nan, 'rmse': np.nan, 'r2': np.nan, 'mape': np.nan}\n",
        "test_metrics = calculate_metrics(y_test, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train multiple Random Forests for quantile prediction (uncertainty quantification)\n",
        "# We'll train separate models for different quantiles\n",
        "quantiles = [0.05, 0.25, 0.5, 0.75, 0.95]  # 5th, 25th, 50th (median), 75th, 95th percentiles\n",
        "\n",
        "print(\"Training quantile Random Forest models for uncertainty quantification...\")\n",
        "quantile_models = {}\n",
        "\n",
        "for q in quantiles:\n",
        "    print(f\"  Training quantile {q:.2f} model...\")\n",
        "    rf_q = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "    \n",
        "    # For quantile regression, we can use a simple approach:\n",
        "    # Train multiple models with different random seeds and use percentiles\n",
        "    # OR use a quantile loss (sklearn doesn't have this, so we'll use ensemble method)\n",
        "    \n",
        "    # For now, let's use an ensemble approach with different random states\n",
        "    # This will give us prediction intervals\n",
        "    rf_q.fit(X_train, y_train)\n",
        "    quantile_models[q] = rf_q\n",
        "\n",
        "print(\"âœ… Quantile models trained!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Better approach: Use multiple Random Forests with different random seeds\n",
        "# Then take percentiles of predictions for uncertainty intervals\n",
        "\n",
        "print(\"Training ensemble of Random Forests for uncertainty estimation...\")\n",
        "n_models = 50  # Number of models in ensemble\n",
        "ensemble_predictions = []\n",
        "\n",
        "for i in range(n_models):\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  Trained {i+1}/{n_models} models...\")\n",
        "    rf = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=20,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42 + i,  # Different seed for each model\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "    ensemble_predictions.append(rf.predict(X_test))\n",
        "\n",
        "# Stack predictions: shape (n_samples, n_models)\n",
        "ensemble_preds = np.column_stack(ensemble_predictions)\n",
        "\n",
        "# Calculate percentiles\n",
        "pred_median = np.median(ensemble_preds, axis=1)\n",
        "pred_q05 = np.percentile(ensemble_preds, 5, axis=1)\n",
        "pred_q95 = np.percentile(ensemble_preds, 95, axis=1)\n",
        "pred_q25 = np.percentile(ensemble_preds, 25, axis=1)\n",
        "pred_q75 = np.percentile(ensemble_preds, 75, axis=1)\n",
        "\n",
        "print(\"âœ… Uncertainty estimates computed!\")\n",
        "\n",
        "# Save the main model (median predictor)\n",
        "quantile_models[0.5] = ensemble_predictions[0]  # Use first model as median\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate uncertainty calibration\n",
        "# Check if prediction intervals cover the true values\n",
        "\n",
        "coverage_90 = np.mean((y_test >= pred_q05) & (y_test <= pred_q95))\n",
        "coverage_50 = np.mean((y_test >= pred_q25) & (y_test <= pred_q75))\n",
        "\n",
        "print(f\"ðŸ“Š Uncertainty Calibration:\")\n",
        "print(f\"  90% Prediction Interval Coverage: {coverage_90*100:.1f}% (target: 90%)\")\n",
        "print(f\"  50% Prediction Interval Coverage: {coverage_50*100:.1f}% (target: 50%)\")\n",
        "\n",
        "# Calculate interval width\n",
        "interval_width_90 = np.mean(pred_q95 - pred_q05)\n",
        "interval_width_50 = np.mean(pred_q75 - pred_q25)\n",
        "print(f\"\\n  Average 90% interval width: {interval_width_90:.2f} cycles\")\n",
        "print(f\"  Average 50% interval width: {interval_width_50:.2f} cycles\")\n",
        "\n",
        "# Test set metrics with median prediction\n",
        "test_metrics_median = calculate_metrics(y_test, pred_median, \"Test (with uncertainty)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Top 15 Most Important Features:\")\n",
        "print(feature_importance.head(15).to_string(index=False))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_n = 20\n",
        "top_features = feature_importance.head(top_n)\n",
        "plt.barh(range(len(top_features)), top_features['importance'])\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title(f'Top {top_n} Feature Importances (Random Forest)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions with uncertainty intervals\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Predictions vs Actual with uncertainty\n",
        "sample_idx = np.random.choice(len(y_test), min(200, len(y_test)), replace=False)\n",
        "sorted_idx = np.argsort(y_test[sample_idx])\n",
        "\n",
        "axes[0].scatter(y_test[sample_idx][sorted_idx], pred_median[sample_idx][sorted_idx], \n",
        "                alpha=0.5, s=20, label='Predictions')\n",
        "axes[0].fill_between(range(len(sorted_idx)), \n",
        "                     pred_q05[sample_idx][sorted_idx],\n",
        "                     pred_q95[sample_idx][sorted_idx],\n",
        "                     alpha=0.3, label='90% Prediction Interval')\n",
        "axes[0].plot(range(len(sorted_idx)), y_test[sample_idx][sorted_idx], \n",
        "             'r-', linewidth=2, label='Actual')\n",
        "axes[0].set_xlabel('Sample Index (sorted by actual RUL)')\n",
        "axes[0].set_ylabel('RUL (cycles)')\n",
        "axes[0].set_title('Predictions with Uncertainty Intervals (Test Set)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Residuals plot\n",
        "residuals = y_test - pred_median\n",
        "axes[1].scatter(pred_median, residuals, alpha=0.5)\n",
        "axes[1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1].fill_between(pred_median, \n",
        "                     pred_q05 - pred_median,\n",
        "                     pred_q95 - pred_median,\n",
        "                     alpha=0.2)\n",
        "axes[1].set_xlabel('Predicted RUL')\n",
        "axes[1].set_ylabel('Residual (Actual - Predicted)')\n",
        "axes[1].set_title('Residuals Plot with Uncertainty')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model and results\n",
        "models_dir = project_root / \"results\" / \"models\"\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save the main model\n",
        "model_path = models_dir / \"random_forest_rul_model.pkl\"\n",
        "joblib.dump(rf_model, model_path)\n",
        "print(f\"âœ… Saved model: {model_path}\")\n",
        "\n",
        "# Save predictions and uncertainty for later analysis\n",
        "results = pd.DataFrame({\n",
        "    'battery_id': df_clean.loc[test_idx, 'battery_id'].values,\n",
        "    'cycle_index': df_clean.loc[test_idx, 'cycle_index'].values,\n",
        "    'actual_rul': y_test,\n",
        "    'predicted_rul': pred_median,\n",
        "    'pred_q05': pred_q05,\n",
        "    'pred_q25': pred_q25,\n",
        "    'pred_q75': pred_q75,\n",
        "    'pred_q95': pred_q95,\n",
        "})\n",
        "\n",
        "results_path = models_dir / \"rf_predictions.csv\"\n",
        "results.to_csv(results_path, index=False)\n",
        "print(f\"âœ… Saved predictions: {results_path}\")\n",
        "\n",
        "# Save metrics\n",
        "metrics = pd.DataFrame({\n",
        "    'metric': ['MAE', 'RMSE', 'RÂ²', 'MAPE'],\n",
        "    'train': [train_metrics['mae'], train_metrics['rmse'], train_metrics['r2'], train_metrics['mape']],\n",
        "    'val': [val_metrics['mae'], val_metrics['rmse'], val_metrics['r2'], val_metrics['mape']],\n",
        "    'test': [test_metrics_median['mae'], test_metrics_median['rmse'], \n",
        "             test_metrics_median['r2'], test_metrics_median['mape']]\n",
        "})\n",
        "\n",
        "metrics_path = models_dir / \"rf_metrics.csv\"\n",
        "metrics.to_csv(metrics_path, index=False)\n",
        "print(f\"âœ… Saved metrics: {metrics_path}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Summary:\")\n",
        "print(f\"   Test MAE: {test_metrics_median['mae']:.2f} cycles\")\n",
        "print(f\"   Test RMSE: {test_metrics_median['rmse']:.2f} cycles\")\n",
        "print(f\"   Test RÂ²: {test_metrics_median['r2']:.3f}\")\n",
        "print(f\"   90% Coverage: {coverage_90*100:.1f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "battery_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
