{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train LSTM Model (Point Prediction)\n",
        "\n",
        "This notebook trains an LSTM model for RUL prediction using sequences of past cycles.\n",
        "\n",
        "**Phase 1**: Point prediction only - no uncertainty quantification.\n",
        "**Phase 2**: Monte Carlo Dropout will be added in `06_add_uncertainty_lstm_mc.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# TensorFlow for LSTM\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(\"/Users/siddhantaggarwal/Desktop/Battery_RUL\").resolve()\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset with EMD features\n",
        "processed_dir = project_root / \"data\" / \"processed\"\n",
        "df = pd.read_parquet(processed_dir / \"rul_features_with_emd.parquet\")\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "\n",
        "# Filter out rows with NaN RUL\n",
        "df_clean = df[df['RUL'].notna()].copy()\n",
        "print(f\"After removing NaN RUL: {len(df_clean)} rows\")\n",
        "print(f\"RUL range: [{df_clean['RUL'].min():.1f}, {df_clean['RUL'].max():.1f}] cycles\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features\n",
        "exclude_cols = [\n",
        "    'battery_id', 'filename', 'type', 'start_time', 'test_id', 'uid',\n",
        "    'split', 'cycle_index', 'EOL_cycle', 'RUL', 'SOH', 'Capacity', \n",
        "    'Re', 'Rct', 'ambient_temperature'\n",
        "]\n",
        "\n",
        "feature_cols = [c for c in df_clean.columns if c not in exclude_cols]\n",
        "print(f\"Total features: {len(feature_cols)}\")\n",
        "\n",
        "# Split by battery\n",
        "train_idx = df_clean['split'] == 'train'\n",
        "test_idx = df_clean['split'] == 'test'\n",
        "\n",
        "df_train = df_clean[train_idx].copy()\n",
        "df_test = df_clean[test_idx].copy()\n",
        "\n",
        "print(f\"Train: {len(df_train)}, Test: {len(df_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sequences for LSTM\n",
        "# Use past N cycles to predict RUL at current cycle\n",
        "sequence_length = 20  # Number of past cycles to use\n",
        "\n",
        "def create_sequences(df_subset, feature_cols, target_col, seq_len=sequence_length):\n",
        "    \"\"\"Create sequences for LSTM training.\"\"\"\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    \n",
        "    for battery_id in df_subset['battery_id'].unique():\n",
        "        battery_data = df_subset[df_subset['battery_id'] == battery_id].sort_values('cycle_index')\n",
        "        \n",
        "        # Extract features and target\n",
        "        features = battery_data[feature_cols].fillna(0).values\n",
        "        target = battery_data[target_col].values\n",
        "        \n",
        "        # Create sequences (need at least seq_len cycles)\n",
        "        if len(features) >= seq_len:\n",
        "            for i in range(seq_len, len(features)):\n",
        "                sequences.append(features[i-seq_len:i])\n",
        "                targets.append(target[i])\n",
        "    \n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "# Create sequences\n",
        "print(f\"Creating sequences with length {sequence_length}...\")\n",
        "X_train_seq, y_train_seq = create_sequences(df_train, feature_cols, 'RUL', sequence_length)\n",
        "X_test_seq, y_test_seq = create_sequences(df_test, feature_cols, 'RUL', sequence_length)\n",
        "\n",
        "print(f\"Train sequences: {X_train_seq.shape}\")\n",
        "print(f\"Test sequences: {X_test_seq.shape}\")\n",
        "print(f\"Feature shape per timestep: {X_train_seq.shape[2]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize features\n",
        "# Reshape for scaling (treat each timestep independently)\n",
        "n_samples, n_timesteps, n_features = X_train_seq.shape\n",
        "X_train_reshaped = X_train_seq.reshape(-1, n_features)\n",
        "X_test_reshaped = X_test_seq.reshape(-1, n_features)\n",
        "\n",
        "# Fit scaler on training data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
        "X_test_scaled = scaler.transform(X_test_reshaped)\n",
        "\n",
        "# Reshape back\n",
        "X_train_seq = X_train_scaled.reshape(n_samples, n_timesteps, n_features)\n",
        "X_test_seq = X_test_scaled.reshape(X_test_seq.shape[0], n_timesteps, n_features)\n",
        "\n",
        "print(\"âœ… Features normalized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build LSTM model (point prediction - no dropout for now)\n",
        "model = keras.Sequential([\n",
        "    layers.LSTM(64, return_sequences=True, input_shape=(sequence_length, len(feature_cols))),\n",
        "    layers.LSTM(32, return_sequences=False),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(1)  # Single output for RUL prediction\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Split train into train/val for early stopping\n",
        "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
        "    X_train_seq, y_train_seq, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_final, y_train_final,\n",
        "    validation_data=(X_val_final, y_val_final),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"âœ… Model trained!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "def calculate_metrics(y_true, y_pred, name):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + 1e-6))) * 100\n",
        "    \n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(f\"  MAE:  {mae:.2f} cycles\")\n",
        "    print(f\"  RMSE: {rmse:.2f} cycles\")\n",
        "    print(f\"  RÂ²:   {r2:.3f}\")\n",
        "    print(f\"  MAPE: {mape:.2f}%\")\n",
        "    return {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train_seq, verbose=0).flatten()\n",
        "y_test_pred = model.predict(X_test_seq, verbose=0).flatten()\n",
        "\n",
        "# Metrics\n",
        "train_metrics = calculate_metrics(y_train_seq, y_train_pred, \"Train\")\n",
        "test_metrics = calculate_metrics(y_test_seq, y_test_pred, \"Test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].plot(history.history['loss'], label='Train Loss')\n",
        "axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss (MSE)')\n",
        "axes[0].set_title('Training History - Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(history.history['mae'], label='Train MAE')\n",
        "axes[1].plot(history.history['val_mae'], label='Val MAE')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('MAE')\n",
        "axes[1].set_title('Training History - MAE')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model and results\n",
        "models_dir = project_root / \"results\" / \"models\"\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "model_path = models_dir / \"lstm_rul_point_model.h5\"\n",
        "model.save(model_path)\n",
        "print(f\"âœ… Saved model: {model_path}\")\n",
        "\n",
        "# Save scaler\n",
        "scaler_path = models_dir / \"lstm_scaler.pkl\"\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f\"âœ… Saved scaler: {scaler_path}\")\n",
        "\n",
        "# Save predictions\n",
        "results = pd.DataFrame({\n",
        "    'actual_rul': y_test_seq,\n",
        "    'predicted_rul': y_test_pred\n",
        "})\n",
        "\n",
        "results_path = models_dir / \"lstm_predictions_point.csv\"\n",
        "results.to_csv(results_path, index=False)\n",
        "print(f\"âœ… Saved predictions: {results_path}\")\n",
        "\n",
        "# Save metrics\n",
        "metrics = pd.DataFrame({\n",
        "    'metric': ['MAE', 'RMSE', 'RÂ²', 'MAPE'],\n",
        "    'train': [train_metrics['mae'], train_metrics['rmse'], train_metrics['r2'], train_metrics['mape']],\n",
        "    'test': [test_metrics['mae'], test_metrics['rmse'], test_metrics['r2'], test_metrics['mape']]\n",
        "})\n",
        "\n",
        "metrics_path = models_dir / \"lstm_metrics_point.csv\"\n",
        "metrics.to_csv(metrics_path, index=False)\n",
        "print(f\"âœ… Saved metrics: {metrics_path}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Summary:\")\n",
        "print(f\"   Test MAE: {test_metrics['mae']:.2f} cycles\")\n",
        "print(f\"   Test RMSE: {test_metrics['rmse']:.2f} cycles\")\n",
        "print(f\"   Test RÂ²: {test_metrics['r2']:.3f}\")\n",
        "print(f\"\\nâœ… Phase 1 Complete: LSTM point prediction model saved!\")\n",
        "print(f\"   Next: Train Transformer model, then compare all 3.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
